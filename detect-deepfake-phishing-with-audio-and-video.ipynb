{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bd8b3d",
   "metadata": {},
   "source": [
    "# Detect Deepfake Phishing Attacks\n",
    "\n",
    "3/24/2025, Dave Sisk, https://github.com/davidcsisk, https://www.linkedin.com/in/davesisk-doctordatabase/\n",
    "\n",
    "A number of AI-driven multi-model deepfake exploits have garnered much attention over the past year, including deepfaked audio/video phishing email of the company's CEO instructing employees to make a funds transfer, and even a CEO himself being deepfaked into transferring company funds to a fake corporate headquarters.  Let's examine how we can put together tools from the AI/ML/data science realm to detect this type of deepfake attack. \n",
    "\n",
    "By \"multi-modal\", I'm referring to attacks delivered as communications that might include text, audio, and video content. \n",
    "\n",
    "Based on results from a 2024 poll conducted by Deloitte, **24.9% of 2190 C-suite and executives say that their organization has experienced one or more deepfake attacks on financial and accounting targets**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0beabcc0",
   "metadata": {},
   "source": [
    "## Examples of real-world attacks from 2024 - present\n",
    "\n",
    "Deepfaked CEO scam attempt: https://www.theguardian.com/technology/article/2024/may/10/ceo-wpp-deepfake-scam\n",
    "\n",
    "Private video sharing phishing attack: https://incidentdatabase.ai/cite/965#r4845\n",
    "\n",
    "Deepfaked Brad Pitt and the $850K romance scam:  https://incidentdatabase.ai/cite/901/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b56f1013",
   "metadata": {},
   "source": [
    "#### The proposed AI-driven Attack Detection Framework:\n",
    "![CybersecurityAI-AnomalyDetection-Flowchart.jpg](.\\CybersecurityAI-AnomalyDetection-Flowchart.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c823a4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Fabricated Example Attacks For Analysis:\n",
    "The fabricated artifacts below were designed to appear realistic and relevant to our organization."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259aa4ef",
   "metadata": {},
   "source": [
    "**If an audio message like the one below came in what appeared to be an official communication, how believable would it be?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4fffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio using the default OS audio player\n",
    "wav_file = './deepfake_DonaldTrump-audio.wav'\n",
    "!start {wav_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d694bdb",
   "metadata": {},
   "source": [
    "**If a video message similar to the one below was sent to all employees from what appeared to be an official source, how believable would it be?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the video using the default OS video player\n",
    "video_file = './deepfake_ElonMusk_SocialSecurityPhishing.mp4'\n",
    "!start {video_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aa8a9",
   "metadata": {},
   "source": [
    "I used inexpensive and readily-available AI tech to create both of these deepfakes.  If these examples are not believable enough, consider that it's simply a matter of using better models and tech to create deepfakes.  Overall, the obvious answer to the question at hand is this:  These are believable enough to potentially cause harm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8b7afc9",
   "metadata": {},
   "source": [
    "## Build library of known phishing attacks\n",
    "In the proposed framework, this datastore of known attacks would be built over time by the reinforcement learning loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bc16cf87",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Dave Sisk\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(34, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the datastore of known phishing emails (30 samples)\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress the FutureWarning from transformers\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='transformers.tokenization_utils_base')\n",
    "\n",
    "# Load the CSV into a pandas dataframe\n",
    "exploit_df = pd.read_csv('./deepfake_phishing_examples.csv')\n",
    "\n",
    "# Ensure 'Subject' and 'Body' columns exist, create them if missing\n",
    "if 'Subject' not in exploit_df.columns:\n",
    "    exploit_df['Subject'] = ''\n",
    "if 'Body' not in exploit_df.columns:\n",
    "    exploit_df['Body'] = ''\n",
    "\n",
    "# Initialize the sentence-transformers model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Combine Subject and Body into a single column for embedding, handling empty values\n",
    "exploit_df['Subject'] = exploit_df['Subject'].fillna('')\n",
    "exploit_df['Body'] = exploit_df['Body'].fillna('')\n",
    "exploit_df['combined_text'] = (exploit_df['Subject'] + ' ' + exploit_df['Body']).str.strip()\n",
    "\n",
    "# Calculate embeddings for the combined text\n",
    "exploit_df['embeddings'] = exploit_df['combined_text'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Function to perform cosine similarity search\n",
    "def search_similar(query, top_n=3):\n",
    "    query_embedding = model.encode(query).reshape(1, -1)\n",
    "    embeddings = np.vstack(exploit_df['embeddings'].values)\n",
    "    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    results = exploit_df.iloc[top_indices][['Subject', 'Body', 'combined_text']].copy()\n",
    "    results['similarity_score'] = similarities[top_indices]\n",
    "    results['preview'] = results['combined_text'].apply(lambda x: x[:100] if x else 'No content available')\n",
    "    return results[['preview', 'similarity_score']]\n",
    "\n",
    "exploit_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c3ae0ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>Escrow Compliance Exception</td>\n",
       "      <td>Move $102,000 as per the escrow directive. Leg...</td>\n",
       "      <td>Escrow Compliance Exception Move $102,000 as p...</td>\n",
       "      <td>[0.054614913, 0.02986592, -0.015277118, -0.040...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Re: Final Settlement</td>\n",
       "      <td>As discussed, please finalize the $150,000 pay...</td>\n",
       "      <td>Re: Final Settlement As discussed, please fina...</td>\n",
       "      <td>[-0.039154477, 0.07341119, 0.036629, -0.068680...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>RE: Reimbursement Urgency</td>\n",
       "      <td>Due to an internal booking error, reimburse $4...</td>\n",
       "      <td>RE: Reimbursement Urgency Due to an internal b...</td>\n",
       "      <td>[-0.025269803, 0.098000735, -0.02679673, 0.023...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                        Subject  \\\n",
       "31  Escrow Compliance Exception   \n",
       "8          Re: Final Settlement   \n",
       "16    RE: Reimbursement Urgency   \n",
       "\n",
       "                                                 Body  \\\n",
       "31  Move $102,000 as per the escrow directive. Leg...   \n",
       "8   As discussed, please finalize the $150,000 pay...   \n",
       "16  Due to an internal booking error, reimburse $4...   \n",
       "\n",
       "                                        combined_text  \\\n",
       "31  Escrow Compliance Exception Move $102,000 as p...   \n",
       "8   Re: Final Settlement As discussed, please fina...   \n",
       "16  RE: Reimbursement Urgency Due to an internal b...   \n",
       "\n",
       "                                           embeddings  \n",
       "31  [0.054614913, 0.02986592, -0.015277118, -0.040...  \n",
       "8   [-0.039154477, 0.07341119, 0.036629, -0.068680...  \n",
       "16  [-0.025269803, 0.098000735, -0.02679673, 0.023...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exploit_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5a780956",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              preview  similarity_score\n",
      "3   Urgent from Mobile I’m traveling and can’t acc...          0.497088\n",
      "7   Immediate Compliance Wire I’ve been told we ha...          0.489520\n",
      "22  Banking Delay Mitigation I’ve been notified th...          0.480011\n",
      "13  Transfer Instruction: Urgent Initiate a transf...          0.461940\n",
      "0   Urgent Wire Transfer – Confidential Hi [Employ...          0.421657\n"
     ]
    }
   ],
   "source": [
    "# Example query with a custom number of top matches\n",
    "query = \"urgent action required for account security\"\n",
    "top_n = 5  # Specify the number of top matches to return\n",
    "results = search_similar(query, top_n=top_n)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9434c004",
   "metadata": {},
   "source": [
    "In practice, we would build this library via the reinforcement learning loop at the bottom right in the framework flowchart.  This means that we would start with little or no examples, and accumulate them as we proceeded, eventually amassing a large library of labeled data as examples. \n",
    "\n",
    "Also in practice, these vector search queries would be run against a vector database hydrated with the above-mentioned data instead of against a temporary in-memory dataframe."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba089f8",
   "metadata": {},
   "source": [
    "## Pre-processing of Working Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e5440",
   "metadata": {},
   "source": [
    "Our first order of business is to get text transcriptions of the messages in these examples, so we can keep any vector search functionality in the text-only realm where we have known good models for that functionality. We'll leverage AI tooling to accomplish these transcriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1f25f",
   "metadata": {},
   "source": [
    "### Audio message\n",
    "We can transcribe from the WAV audio file directly using the smallest open-source Vosk model that has an internalized language graph...this should produce a reasonably accurate transcription. (If the audio were in compressed MP3 file format [very likely if it came in an email, for instance], we'd have to convert it to WAV audio format first, then transcrible the text from that. That's merely a requirement of this particular model though, not the overall technology.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5d18b70",
   "metadata": {},
   "source": [
    "We will use the Vosk models for transcription...these are small in size, free/open-source, and run locally, meaning no data leaves the current host in API calls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dcd306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install vosk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f338cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Audio Text:\n",
      " hi shane i'm following up on the audit readiness review\n",
      "issue in q one expenses for contractor payments we need to\n",
      "transfer one thirty seven thousand eight hundred twenty\n",
      "dollar zero sense to the holding account a b c one twenty\n",
      "three this must be sent by three pm today so do d o g e can\n",
      "reflected in the pre-ordered submission let me know once the\n",
      "transfer is done thanks\n"
     ]
    }
   ],
   "source": [
    "# Let's start with the audio transcription\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Load the 2nd smallest Vosk model\n",
    "model = Model(\"./vosk-model-en-us-0.22-lgraph\")\n",
    "\n",
    "wav_file = './deepfake_DonaldTrump-audio.wav'\n",
    "\n",
    "# Open the audio file\n",
    "with wave.open(wav_file, \"rb\") as wf:\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [8000, 16000]:\n",
    "        raise ValueError(\"Audio file must be WAV format mono PCM.\")\n",
    "    \n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "    recognizer.SetWords(True)\n",
    "    \n",
    "    transcription = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            transcription.append(result.get(\"text\", \"\"))\n",
    "    \n",
    "    # Get the final transcription\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    transcription.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "# Combine all parts of the transcription\n",
    "transcribed_text_audio = \" \".join(transcription)\n",
    "\n",
    "# Wrap the text for better readability\n",
    "wrapped_text_audio = textwrap.fill(transcribed_text_audio, width=60)\n",
    "print(\"Transcribed Audio Text:\\n\", wrapped_text_audio)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "543b414a",
   "metadata": {},
   "source": [
    "Next, we'll transcribe text from the audio track on the video to get the exploit message.  This requires multiple steps to get the audio track from the video, then transcribe text from the audio. Extracting audio from the video is easy and deterministic...typical tooling can be used for that task.  AI tech is again needed to transcribe the audio to text...we'll use the same Vosk models for the text transcription. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f1d3e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './deepfake_ElonMusk_SocialSecurityPhishing.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:23.42, start: 0.000000, bitrate: 501 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x480 [SAR 1:1 DAR 1:1], 425 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to './extracted_audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 0000027165bf4d00] video:0KiB audio:732KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.010406%\n",
      "size=     732KiB time=00:00:23.42 bitrate= 256.0kbits/s speed=1.74e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribed Video Text:\n",
      " greetings valued employees immediate action is needed from\n",
      "you please go to the listed u r l logging into your social\n",
      "security account and change your password this will provide\n",
      "a immediate flag that your social security account is valid\n",
      "please complete this task task by five pm today thank you\n"
     ]
    }
   ],
   "source": [
    "# Let's transcribe text from the video\n",
    "import os\n",
    "import wave\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Load the Vosk model\n",
    "model = Model(\"./vosk-model-en-us-0.22-lgraph\")\n",
    "\n",
    "# Path to the video file\n",
    "video_file = './deepfake_ElonMusk_SocialSecurityPhishing.mp4'\n",
    "audio_file = './extracted_audio.wav'\n",
    "\n",
    "# Delete the extracted audio file if it already exists\n",
    "if os.path.exists(audio_file):\n",
    "    os.remove(audio_file)\n",
    "\n",
    "# Extract audio using ffmpeg (no moviepy)\n",
    "!ffmpeg -i {video_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 {audio_file}\n",
    "\n",
    "# Transcribe the extracted audio\n",
    "with wave.open(audio_file, \"rb\") as wf:\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [8000, 16000]:\n",
    "        raise ValueError(\"Audio file must be WAV format mono PCM.\")\n",
    "    \n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "    recognizer.SetWords(True)\n",
    "    \n",
    "    transcription = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            transcription.append(result.get(\"text\", \"\"))\n",
    "    \n",
    "    # Get the final transcription\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    transcription.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "# Combine all parts of the transcription\n",
    "transcribed_text_video = \" \".join(transcription)\n",
    "\n",
    "# Wrap the text for better readability\n",
    "wrapped_text_video = textwrap.fill(transcribed_text_video, width=60)\n",
    "print(\"\\nTranscribed Video Text:\\n\", wrapped_text_video)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21bd3c",
   "metadata": {},
   "source": [
    "## Take these examples combined with typical non-attack communications, and run them through the proposed process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e697bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the CSV file into a pandas dataframe\n",
    "incoming_df = pd.read_csv('./corporate_communication_examples.csv')\n",
    "\n",
    "# Add the transcribed audio and video text as new rows\n",
    "incoming_df = pd.concat([\n",
    "    incoming_df,\n",
    "    pd.DataFrame({'Subject': ['Action required: Transfer by 3pm todayTranscribed Audio'], 'Body': [transcribed_text_audio]}),\n",
    "    pd.DataFrame({'Subject': ['Message to all employees'], 'Body': [transcribed_text_video]})\n",
    "], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "541de376",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>Team Building Activity</td>\n",
       "      <td>This is a friendly reminder to submit your tim...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>Client Follow-up Required</td>\n",
       "      <td>Attached is the latest draft of the policy doc...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Message to all employees</td>\n",
       "      <td>greetings valued employees immediate action is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Subject  \\\n",
       "91      Team Building Activity   \n",
       "34   Client Follow-up Required   \n",
       "101   Message to all employees   \n",
       "\n",
       "                                                  Body  \n",
       "91   This is a friendly reminder to submit your tim...  \n",
       "34   Attached is the latest draft of the policy doc...  \n",
       "101  greetings valued employees immediate action is...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Display the first few rows of the dataframe to verify the data\n",
    "incoming_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2926a61e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>Internal Survey Participation</td>\n",
       "      <td>Please confirm your attendance for next Thursd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Action required: Transfer by 3pm todayTranscri...</td>\n",
       "      <td>hi shane i'm following up on the audit readine...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>Message to all employees</td>\n",
       "      <td>greetings valued employees immediate action is...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Subject  \\\n",
       "99                       Internal Survey Participation   \n",
       "100  Action required: Transfer by 3pm todayTranscri...   \n",
       "101                           Message to all employees   \n",
       "\n",
       "                                                  Body  \n",
       "99   Please confirm your attendance for next Thursd...  \n",
       "100  hi shane i'm following up on the audit readine...  \n",
       "101  greetings valued employees immediate action is...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "incoming_df.tail(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6044b9c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f2c0bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
