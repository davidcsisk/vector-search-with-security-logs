{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "66bd8b3d",
   "metadata": {},
   "source": [
    "# Detect Deepfake Phishing Multi-Model Attacks\n",
    "\n",
    "3/24/2025, Dave Sisk, https://github.com/davidcsisk, https://www.linkedin.com/in/davesisk-doctordatabase/\n",
    "\n",
    "A number of AI-driven deepfake exploits have garnered much attention over the past year, including deepfaked audio/video phishing email of the company's CEO instructing employees to make a funds transfer, and even a CEO himself being deepfaked into transferring company funds to a fake corporate headquarters.  Let's examine how we can put together tools from the AI/ML/data science realm to detect this type of deepfake attack. \n",
    "\n",
    "By \"multi-model\", I'm referring to attacks delivered as communications that might include text, audio, and video content. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c823a4b",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## Working Examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259aa4ef",
   "metadata": {},
   "source": [
    "If an audio message like the one below came in what appeared to be an official communication, how believable would it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2c4fffa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the audio using the default OS audio player\n",
    "wav_file = './/vector-search-with-security-logs//deepfake_DonaldTrump-audio.wav'\n",
    "!start {wav_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d694bdb",
   "metadata": {},
   "source": [
    "If a video message similar to the one below was sent to all employees from what appeared to be an official source, how believable would it be?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f07e35e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Play the video using the default OS video player\n",
    "video_file = './vector-search-with-security-logs/deepfake_ElonMusk_SocialSecurityPhishing.mp4'\n",
    "!start {video_file}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989aa8a9",
   "metadata": {},
   "source": [
    "If these examples are not believable enough, consider that it's simply a matter of using better models to create those deepfakes.  Overall, the obvious answer to the question at hand is this:  These are believable enough to potentially cause harm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ba089f8",
   "metadata": {},
   "source": [
    "## Pre-processing of Working Examples"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d70e5440",
   "metadata": {},
   "source": [
    "Our first order of business is to get text transcriptions of the messages in these examples, so we can keep any vector search functionality in the text-only realm where we have known good models for that functionality. We'll leverage AI tooling to accomplish these transcriptions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25e1f25f",
   "metadata": {},
   "source": [
    "### Audio message\n",
    "We can transcribe from the WAV audio file directly using the smallest open-source Vosk model that has an internalized language graph...this should produce a reasonably accurate transcription. (If the audio were in compressed MP3 file format [very likely if it came in an email, for instance], we'd have to convert it to WAV audio format first, then transcrible the text from that. That's merely a requirement of this particular model though, not the overall technology.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8dcd306d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#! pip install moviepy\n",
    "#! pip install vosk\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f338cd02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcribed Text:\n",
      " hi shane i'm following up on the audit readiness review issue in q one expenses\n",
      "for contractor payments we need to transfer one thirty seven thousand eight\n",
      "hundred twenty dollar zero sense to the holding account a b c one twenty three\n",
      "this must be sent by three pm today so do d o g e can reflected in the pre-\n",
      "ordered submission let me know once the transfer is done thanks\n"
     ]
    }
   ],
   "source": [
    "from vosk import Model, KaldiRecognizer\n",
    "import wave\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Load the 2nd smallest Vosk model\n",
    "model = Model(\".//vector-search-with-security-logs//vosk-model-en-us-0.22-lgraph\")\n",
    "\n",
    "wav_file = './/vector-search-with-security-logs//deepfake_DonaldTrump-audio.wav'\n",
    "\n",
    "# Open the audio file\n",
    "with wave.open(wav_file, \"rb\") as wf:\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [8000, 16000]:\n",
    "        raise ValueError(\"Audio file must be WAV format mono PCM.\")\n",
    "    \n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "    recognizer.SetWords(True)\n",
    "    \n",
    "    transcription = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            transcription.append(result.get(\"text\", \"\"))\n",
    "    \n",
    "    # Get the final transcription\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    transcription.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "# Combine all parts of the transcription\n",
    "transcribed_text = \" \".join(transcription)\n",
    "\n",
    "# Wrap the text for better readability\n",
    "wrapped_text = textwrap.fill(transcribed_text, width=80)\n",
    "print(\"Transcribed Text:\\n\", wrapped_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1d3e1e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1-essentials_build-www.gyan.dev Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with gcc 14.2.0 (Rev1, Built by MSYS2 project)\n",
      "  configuration: --enable-gpl --enable-version3 --enable-static --disable-w32threads --disable-autodetect --enable-fontconfig --enable-iconv --enable-gnutls --enable-libxml2 --enable-gmp --enable-bzlib --enable-lzma --enable-zlib --enable-libsrt --enable-libssh --enable-libzmq --enable-avisynth --enable-sdl2 --enable-libwebp --enable-libx264 --enable-libx265 --enable-libxvid --enable-libaom --enable-libopenjpeg --enable-libvpx --enable-mediafoundation --enable-libass --enable-libfreetype --enable-libfribidi --enable-libharfbuzz --enable-libvidstab --enable-libvmaf --enable-libzimg --enable-amf --enable-cuda-llvm --enable-cuvid --enable-dxva2 --enable-d3d11va --enable-d3d12va --enable-ffnvcodec --enable-libvpl --enable-nvdec --enable-nvenc --enable-vaapi --enable-libgme --enable-libopenmpt --enable-libopencore-amrwb --enable-libmp3lame --enable-libtheora --enable-libvo-amrwbenc --enable-libgsm --enable-libopencore-amrnb --enable-libopus --enable-libspeex --enable-libvorbis --enable-librubberband\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from './/vector-search-with-security-logs//deepfake_ElonMusk_SocialSecurityPhishing.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    encoder         : Lavf58.29.100\n",
      "  Duration: 00:00:23.42, start: 0.000000, bitrate: 501 kb/s\n",
      "  Stream #0:0[0x1](und): Video: h264 (High) (avc1 / 0x31637661), yuv420p(progressive), 480x480 [SAR 1:1 DAR 1:1], 425 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "  Stream #0:1[0x2](und): Audio: aac (LC) (mp4a / 0x6134706D), 48000 Hz, mono, fltp, 69 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "Stream mapping:\n",
      "  Stream #0:1 -> #0:0 (aac (native) -> pcm_s16le (native))\n",
      "Press [q] to stop, [?] for help\n",
      "Output #0, wav, to './/vector-search-with-security-logs//extracted_audio.wav':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2avc1mp41\n",
      "    ISFT            : Lavf61.7.100\n",
      "  Stream #0:0(und): Audio: pcm_s16le ([1][0][0][0] / 0x0001), 16000 Hz, mono, s16, 256 kb/s (default)\n",
      "      Metadata:\n",
      "        handler_name    : SoundHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.101 pcm_s16le\n",
      "[out#0/wav @ 000001b7123baa40] video:0KiB audio:732KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.010406%\n",
      "size=     732KiB time=00:00:23.42 bitrate= 256.0kbits/s speed=1.9e+03x    \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transcribed Text:\n",
      " greetings valued employees immediate action is needed from you please go to the\n",
      "listed u r l logging into your social security account and change your password\n",
      "this will provide a immediate flag that your social security account is valid\n",
      "please complete this task task by five pm today thank you\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import wave\n",
    "from vosk import Model, KaldiRecognizer\n",
    "import json\n",
    "import textwrap\n",
    "\n",
    "# Load the Vosk model\n",
    "model = Model(\".//vector-search-with-security-logs//vosk-model-en-us-0.22-lgraph\")\n",
    "\n",
    "# Path to the video file\n",
    "video_file = './/vector-search-with-security-logs//deepfake_ElonMusk_SocialSecurityPhishing.mp4'\n",
    "audio_file = './/vector-search-with-security-logs//extracted_audio.wav'\n",
    "\n",
    "# Delete the extracted audio file if it already exists\n",
    "if os.path.exists(audio_file):\n",
    "    os.remove(audio_file)\n",
    "\n",
    "# Extract audio using ffmpeg (no moviepy)\n",
    "!ffmpeg -i {video_file} -vn -acodec pcm_s16le -ar 16000 -ac 1 {audio_file}\n",
    "\n",
    "# Transcribe the extracted audio\n",
    "with wave.open(audio_file, \"rb\") as wf:\n",
    "    if wf.getnchannels() != 1 or wf.getsampwidth() != 2 or wf.getframerate() not in [8000, 16000]:\n",
    "        raise ValueError(\"Audio file must be WAV format mono PCM.\")\n",
    "    \n",
    "    recognizer = KaldiRecognizer(model, wf.getframerate())\n",
    "    recognizer.SetWords(True)\n",
    "    \n",
    "    transcription = []\n",
    "    while True:\n",
    "        data = wf.readframes(4000)\n",
    "        if len(data) == 0:\n",
    "            break\n",
    "        if recognizer.AcceptWaveform(data):\n",
    "            result = json.loads(recognizer.Result())\n",
    "            transcription.append(result.get(\"text\", \"\"))\n",
    "    \n",
    "    # Get the final transcription\n",
    "    final_result = json.loads(recognizer.FinalResult())\n",
    "    transcription.append(final_result.get(\"text\", \"\"))\n",
    "\n",
    "# Combine all parts of the transcription\n",
    "transcribed_text = \" \".join(transcription)\n",
    "\n",
    "# Wrap the text for better readability\n",
    "wrapped_text = textwrap.fill(transcribed_text, width=80)\n",
    "print(\"\\nTranscribed Text:\\n\", wrapped_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b21bd3c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15cb4788",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 4)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Build the datastore of known phishing emails (30 samples)\n",
    "import pandas as pd\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "# Suppress the FutureWarning from transformers\n",
    "warnings.filterwarnings('ignore', category=FutureWarning, module='transformers.tokenization_utils_base')\n",
    "\n",
    "# Load the CSV into a pandas dataframe\n",
    "df = pd.read_csv('.//vector-search-with-security-logs//deepfake_phishing_examples.csv')\n",
    "\n",
    "# Ensure 'Subject' and 'Body' columns exist, create them if missing\n",
    "if 'Subject' not in df.columns:\n",
    "    df['Subject'] = ''\n",
    "if 'Body' not in df.columns:\n",
    "    df['Body'] = ''\n",
    "\n",
    "# Initialize the sentence-transformers model\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "\n",
    "# Combine Subject and Body into a single column for embedding, handling empty values\n",
    "df['Subject'] = df['Subject'].fillna('')\n",
    "df['Body'] = df['Body'].fillna('')\n",
    "df['combined_text'] = (df['Subject'] + ' ' + df['Body']).str.strip()\n",
    "\n",
    "# Calculate embeddings for the combined text\n",
    "df['embeddings'] = df['combined_text'].apply(lambda x: model.encode(x))\n",
    "\n",
    "# Function to perform cosine similarity search\n",
    "def search_similar(query, top_n=3):\n",
    "    query_embedding = model.encode(query).reshape(1, -1)\n",
    "    embeddings = np.vstack(df['embeddings'].values)\n",
    "    similarities = cosine_similarity(query_embedding, embeddings).flatten()\n",
    "    top_indices = similarities.argsort()[-top_n:][::-1]\n",
    "    results = df.iloc[top_indices][['Subject', 'Body', 'combined_text']].copy()\n",
    "    results['similarity_score'] = similarities[top_indices]\n",
    "    results['preview'] = results['combined_text'].apply(lambda x: x[:100] if x else 'No content available')\n",
    "    return results[['preview', 'similarity_score']]\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "de72d32c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject</th>\n",
       "      <th>Body</th>\n",
       "      <th>combined_text</th>\n",
       "      <th>embeddings</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Time-Sensitive Funding Approval</td>\n",
       "      <td>Please move $64,200 to the project fund immedi...</td>\n",
       "      <td>Time-Sensitive Funding Approval Please move $6...</td>\n",
       "      <td>[0.01350849, 0.039254844, 0.011224821, 0.06720...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>Director Request – Time Sensitive</td>\n",
       "      <td>Send $119,000 to ensure project continuation. ...</td>\n",
       "      <td>Director Request – Time Sensitive Send $119,00...</td>\n",
       "      <td>[-0.0680404, 0.020338254, 0.044019964, 0.04546...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Immediate Action Required – Payment Authorization</td>\n",
       "      <td>[Employee Name], I’ve approved the invoice fro...</td>\n",
       "      <td>Immediate Action Required – Payment Authorizat...</td>\n",
       "      <td>[-0.1030883, 0.08535468, -0.013656264, -0.0190...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Subject  \\\n",
       "11                    Time-Sensitive Funding Approval   \n",
       "32                  Director Request – Time Sensitive   \n",
       "1   Immediate Action Required – Payment Authorization   \n",
       "\n",
       "                                                 Body  \\\n",
       "11  Please move $64,200 to the project fund immedi...   \n",
       "32  Send $119,000 to ensure project continuation. ...   \n",
       "1   [Employee Name], I’ve approved the invoice fro...   \n",
       "\n",
       "                                        combined_text  \\\n",
       "11  Time-Sensitive Funding Approval Please move $6...   \n",
       "32  Director Request – Time Sensitive Send $119,00...   \n",
       "1   Immediate Action Required – Payment Authorizat...   \n",
       "\n",
       "                                           embeddings  \n",
       "11  [0.01350849, 0.039254844, 0.011224821, 0.06720...  \n",
       "32  [-0.0680404, 0.020338254, 0.044019964, 0.04546...  \n",
       "1   [-0.1030883, 0.08535468, -0.013656264, -0.0190...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e7def22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                              preview  similarity_score\n",
      "3   Urgent from Mobile I’m traveling and can’t acc...          0.497088\n",
      "7   Immediate Compliance Wire I’ve been told we ha...          0.489520\n",
      "22  Banking Delay Mitigation I’ve been notified th...          0.480011\n",
      "13  Transfer Instruction: Urgent Initiate a transf...          0.461940\n",
      "0   Urgent Wire Transfer – Confidential Hi [Employ...          0.421657\n"
     ]
    }
   ],
   "source": [
    "# Example query with a custom number of top matches\n",
    "query = \"urgent action required for account security\"\n",
    "top_n = 5  # Specify the number of top matches to return\n",
    "results = search_similar(query, top_n=top_n)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220c0adf",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
