{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Neural/AI Search applied to Proxy Logs</u>\n",
    "\n",
    "The intention of this Jupyter notebook is to examine how we might apply AI search to security logs.  We'll be using fabricated proxy logs that (in theory) show benign behavior, malicious behavior, and a 950/50 mix of those two. I hope to demonstrate the following three examples:\n",
    "- Semantic matching: Compare incoming logs to a vector DB of known malicious logs, flagging matches for alert\n",
    "- Anomaly detection: Compare incoming logs to a vector DB of known benign logs, flagging possible anomalies for alert\n",
    "- Full-text Clustering: Show clustering done with full text by leveraging vector embeddings\n",
    "\n",
    "We'll be using a simple development-grade vector datastore called ChromaDB, and a locally-running HuggingFace LLM (large language model) that is a common one of calculating generic vector embeddings of text.\n",
    "\n",
    "Note that there are many synonyms for <b>vector search</b>...here's a list:\n",
    "- Vector similarity search\n",
    "- Semantic similarity search\n",
    "- Neural search (because of it's basis in neural network models for the embeddings)\n",
    "- AI search\n",
    "- KNN search (K-Nearest Neighbors...this is the old and/or conceptual name)\n",
    "- ANN search (Approximate Nearest Neighbors) \n",
    "- HNSW (Hierarchical Navigable Small World) search (the most popular approximation algorithm)\n",
    "- Probably a few others I've forgotten\n",
    "\n",
    "All of these synonyms are referring to the same concepts and technology. It's worth noting that vector search technology has been used in large scale recommendation systems, fraud detection systems, and other \"big data\" types of applications for nearly a decade. In fact, handling very large volumes of full-text data is exactly what this technology was invented to handle. It's also worth noting that vector embeddings are not just relevant to text...given a suitable ML model, vector embeddings can be captured for images, audio, video, even binary executables and encrypted data. "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Preparation steps:\n",
    "python -v venv venv\n",
    "venv\\Scripts\\Activate.ps1\n",
    "pip install pandas\n",
    "pip install scikit-learn\n",
    "pip install chromadb\n",
    "pip install sentence-transformers\n",
    "pip install matplotlib\n",
    "\n",
    "Details from https://github.com/chroma-core/chroma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import pandas as pd \n",
    "import chromadb\n",
    "#from chromadb.config import DEFAULT_TENANT, DEFAULT_DATABASE, Settings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Semantic Matching: Match incoming logs against known malicious logs</u>\n",
    "## Step 1: Hydrate vector DB of malicious logs\n",
    "We can use this vectorstore of known malicious logs as reference data to compare incoming logs against to determine if any of those events are similar enough to raise an alert.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This CSV file contains fabricated proxy logs that are examples of malicious activity attempts\n",
    "df = pd.read_csv('proxy_logs_malicious.csv')\n",
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3) # I've purposefully generated these to look like something that might be extracted from Splunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup Chroma in-memory, for easy prototyping. Can add persistence easily!\n",
    "client = chromadb.Client()\n",
    "#client = chromadb.PersistentClient(path='./chromadb_proxy_logs')  # A bug prevents this from working"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create collection. get_collection, get_or_create_collection, delete_collection also available\n",
    "# ChromaDB uses L2 (Euclidean distance) by default...we want Cosine metric.\n",
    "# Cosine similarity -> higher = better\n",
    "collection = client.get_or_create_collection(name='malicious_proxy_logs', metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add docs to the collection. Can also update and delete.\n",
    "\n",
    "# Create lists of the necessary data from the dataframe\n",
    "ID_list = df['ID'].astype(str).tolist()  # ID list, converted to string\n",
    "LogEntry_list = df['Log Entry'].tolist()   # List of documents (log content)\n",
    "\n",
    "# We are letting ChromaDB automatically calculate the vector embedding, instead of explicitly handling it\n",
    "# By default, ChromaDB uses all-MiniLM-L6-v2 sentence transformer model to calculate vector embeddings\n",
    "# This all-MiniLM-L6-v2 model provides a 384 dimension vector that can be used for embedding and clustering\n",
    "collection.add(\n",
    "    documents=LogEntry_list, # we handle tokenization, embedding, and indexing automatically. You can skip that and add your own embeddings as well\n",
    "    #metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # metadata filters\n",
    "    ids=ID_list, # unique ID for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "First use of vector embedding triggers download of model:\n",
    "C:\\Users\\david\\.cache\\chroma\\onnx_models\\all-MiniLM-L6-v2\\onnx.tar.gz: 100%|██████████| 79.3M/79.3M [00:03<00:00, 27.0MiB/s]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()  # Check our count to make sure it looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Examine a record by ID...tell it to show the vector embedding so we can see what it looks like\n",
    "# The vector embedding is the 384 dimension numeric representation of what that text \"means\"...\n",
    "collection.get('1', include=['embeddings', 'documents', 'metadatas'])\n",
    "#collection.get(['1','2'], include=['embeddings', 'documents', 'metadatas'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's examine simple calcs around vector distance to foster understanding\n",
    "import numpy\n",
    "import math\n",
    "from scipy import spatial\n",
    "\n",
    "# Grab data from two of the records we've put into the vector DB to examine\n",
    "vec1 = collection.get('1', include=['embeddings', 'documents'])['embeddings'][0]\n",
    "vec2 = collection.get('2', include=['embeddings', 'documents'])['embeddings'][0]\n",
    "\n",
    "# Calc the euclidean (or L2) distance between those two vectors\n",
    "# This is the same thing you'd do with geographic distance between 2 cities\n",
    "# Euclidean provides magnitude but not direction...a lower distance is better match\n",
    "euclidean_dist = spatial.distance.euclidean(vec1, vec2)\n",
    "print('euclidean distance (smaller value = more similar): ', euclidean_dist)\n",
    "\n",
    "# Cosine similarity is the difference between angles...it provides direction but not magnitude\n",
    "# Cosine is often a good metric for text comparison...not that a higher value is better match\n",
    "# Cosine example values:\n",
    "# 180 degrees = -1.0\n",
    "# 120 degrees = -0.5\n",
    "#  90 degrees =  0.0\n",
    "#  60 degrees = +0.5\n",
    "#   0 degrees = +1.0\n",
    "cosine_dist = spatial.distance.cosine(vec1, vec2)\n",
    "print('cosine similarity (larger value = more similar): ', cosine_dist)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute an ANN query/search for K most similar results.\n",
    "results = collection.query(\n",
    "    query_texts=[\"http://www.example.com/../../etc/passwd\"], # This gets vectorized and used for vector query\n",
    "    n_results=3,\n",
    "    # where_document={\"$contains\":\"Macintosh\"}  # optional keyword filter\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional metadata filter\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ask the same question, but this time in plain English!\n",
    "results = collection.query(\n",
    "    query_texts=[\"Can you show me possible attempts to change a password?\"],  # Vectorize and search\n",
    "    n_results=3,\n",
    "    # where_document={\"$contains\":\"script\"}  # optional keyword filter\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional metadata filter\n",
    ")\n",
    "\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've built a vector datastore of known malicious logs...we can now use this to compare with logs of an unknown risk."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 2: Semantic matching of malicious attempts\n",
    "Using our vector DB of malicious logs to execute neural searches against, let's feed it some fresh logs to see what matches we get.  We want to use cosine similarity for this.  We'll have to experiment a bit to set a reasonable threshold for when to return an alert vs not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some fabricated proxy logs that contain 950 benign log entries and 50 malicious log entries\n",
    "df = pd.read_csv('proxy_logs_mixed.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find incoming log entries that match known malicious activity at a pre-determined threshold \n",
    "incoming_proxy_logs = df['Log Entry']\n",
    "\n",
    "for log_entry in incoming_proxy_logs:\n",
    "    results = collection.query(\n",
    "    query_texts=log_entry,\n",
    "    n_results=1,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    where_document={\"$contains\":\"Macintosh\"}  # optional filter\n",
    "    )\n",
    "    if results['distances'][0][0] <= 0.001:  # Threshold for a match...this should be the wrong direction!\n",
    "    #if results['distances'][0][0] >= 0.488:  # Threshold for a match\n",
    "    # NOTE:  It appears that ChromaDB is using Euclidean distance even though I specified Cosine similarity\n",
    "    #        Our best matches should be high values, not low values\n",
    "       print(f'Score {results[\"distances\"][0][0]}: {log_entry} \\n -match ID {results[\"ids\"][0]} content: {results[\"documents\"][0][0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We demonstrated here that we can do a vector search comparing incoming log records with a vector DB of known malicious log records, get the top reasonable matches, and do so without any drastic data manipulation. (This is after adjusting for ChromaDB's apparent malfunction with using the specified distance calcs, of course.) In fact, we <b><i>did not even parse any of the log content</i></b>, we just used the vector embeddings of that log content. We are doing semantic matching using the vector embeddings of the full text...this is the important item to take note of.  The data in this case are sets of fabricated proxy logs...this exercise needs to be examined with real logs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Anomaly Detection by AI search on Benign Logs</u>\n",
    "## Step 1: Build vector DB of Benign Proxy log data\n",
    "Now, let's build a vector DB from log data that is good rather than bad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To conserve memory, re-use the previous collection for new data\n",
    "collection = client.get_or_create_collection(name='benign_proxy_logs', metadata={\"hnsw:space\": \"cosine\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This CSV file contains fabricated proxy logs that are examples of benign activity\n",
    "df = pd.read_csv('proxy_logs_good.csv')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lists of the necessary data from the dataframe\n",
    "ID_list = df['ID'].astype(str).tolist()  # ID list, converted to string\n",
    "LogEntry_list = df['Log Entry'].tolist()   # List of documents (log content)\n",
    "\n",
    "# Add log records to vector store, allowing ChromaDB to calculate vector embeddings\n",
    "collection.add(\n",
    "    documents=LogEntry_list, # we handle tokenization, embedding, and indexing automatically. \n",
    "    #metadatas=[{\"source\": \"notion\"}, {\"source\": \"google-docs\"}], # metadata filters\n",
    "    ids=ID_list, # unique ID for each doc\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.count()  # Check our count to make sure it looks right"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check a few records...\n",
    "collection.get(['1','2','3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 1: Vector search for Anomaly Detection\n",
    "With a vector DB of known benign/good proxy log entries, we can do semantic comparison to flag incoming log entries that are <b><i>too different</i></b> from what we know to be benign logs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use fabricated proxy logs that contain 950 benign log entries and 50 malicious log entries again\n",
    "df = pd.read_csv('proxy_logs_mixed.csv')\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's identify anomalies in the incoming logs by using vector search against DB of known benign logs\n",
    "incoming_proxy_logs = df['Log Entry']\n",
    "\n",
    "for log_entry in incoming_proxy_logs:\n",
    "    results = collection.query(\n",
    "    query_texts=log_entry,\n",
    "    n_results=1,\n",
    "    # where={\"metadata_field\": \"is_equal_to_this\"}, # optional filter\n",
    "    # where_document={\"$contains\":\"search_string\"}  # optional filter\n",
    "    )\n",
    "    if results['distances'][0][0] >= 0.3:  # Threshold for a non-match...this should be wrong direction!\n",
    "    #if results['distances'][0][0] <= 0.0001:  # Threshold for a non-match\n",
    "        print(f'Anomaly score {results[\"distances\"][0][0]}: {log_entry} \\n -worst match ID {results[\"ids\"][0]} content: {results[\"documents\"][0][0]}')\n",
    "    \n",
    "    # NOTE:  Again ChromaDB appears to be using Euclidean distance calcs instead of the specified Cosine metric\n",
    "    #        I think perhaps I've uncovered a bug in ChromaDB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've gotten some possible anomalies that appear to be drastic non-matches (after adjusting for ChromaDB's apparent malfunction around using the specified distance calcs, of course). Just like the previous matching exercise, this was done with no parsing or data manipulations of the log data...only the vector embeddings of the log data were used. In practice, we'd likely do some pre-filtering with metadata and keyword matches to apply the vector search to the smallest subset reasonably possible. For anomaly detection, that could be a pretty large data set however.  Regardless, good next steps would be to test this against a sample of real logs and compare what we get."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <u>Full-text Clustering with Vector Embeddings</u>\n",
    "We will use the mixed proxy log data which 950 benign logs + 50 malicious logs to see if we can segregate the two using clustering. This is a notable exercise...only recently has this technology advanced to the point that we can actually do Clustering with full text such as security logs!\n",
    "We are going to feed the clustering algorithms the mixed data with 950 benign logs and 50 malicious logs, and (at least for Kmeans), tell it we want two cluster groups. What we'd like to see if around 950 members land in one of those groups, and around 50 members land in the other group. Let's see how this looks...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# We'll use the mixed proxy logs to see if we can get them clustered into 950 benign + 50 malicious\n",
    "df = pd.read_csv('proxy_logs_mixed.csv')\n",
    "df = df.drop(['IP Address', 'Timestamp'], axis=1)  # We don't need IP nor timestamp for this task\n",
    "df.sample(3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# It's easier to just calc the vector embeddings explicitly, vs adding inserting to ChromaDB to get embeddings\n",
    "# ChromaDB can't do clustering queries (yet), but we will use the same embedding model that ChromaDB is using\n",
    "\n",
    "# Load the embedding model so we can use it to easily populate the dataframe\n",
    "from sentence_transformers import SentenceTransformer\n",
    "model = SentenceTransformer('sentence-transformers/all-MiniLM-L6-v2')\n",
    "# Use like this: embeddings = model.encode(whatever_text)\n",
    "\n",
    "# Use a lambda function to encode the text in each row and apply it to a new column\n",
    "df['embedding'] = df['Log Entry'].apply(lambda text:model.encode(text))\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Extract the embeddings from the DataFrame\n",
    "embeddings = df['embedding'].tolist()\n",
    "\n",
    "# Convert the list of embeddings into a numpy array\n",
    "# import numpy as np\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Perform K-means clustering with K=2\n",
    "# We know we have good logs and bad logs, so let's try to cluster them into good and bad\n",
    "kmeans = KMeans(n_clusters=2, n_init=100, max_iter=3000, random_state=0)\n",
    "#kmeans = KMeans(n_clusters=2, n_init=10, max_iter=300, random_state=0)  # These are defaults\n",
    "#kmeans = KMeans(n_clusters=2, n_init=10000, max_iter=10000, random_state=0)\n",
    "df['cluster_kmeans'] = kmeans.fit_predict(X)\n",
    "\n",
    "# Now `df` will have a new column 'cluster' indicating the cluster each entry belongs to\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hope to see cluster group counts in the ballpark of 950 and 50\n",
    "df['cluster_kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try dimensionality reduction to 2 dimensions from 384, then try re-clustering\n",
    "import pandas as pd\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Extract the embeddings from the DataFrame\n",
    "embeddings = df['embedding'].tolist()\n",
    "\n",
    "# Convert the list of embeddings into a numpy array\n",
    "import numpy as np\n",
    "X = np.array(embeddings)\n",
    "\n",
    "# Perform PCA for dimensionality reduction\n",
    "n_components = 2  # Number of dimensions to reduce to\n",
    "pca = PCA(n_components=n_components)\n",
    "principal_components = pca.fit_transform(X)\n",
    "\n",
    "# Add the principal components to the DataFrame\n",
    "df_pca = pd.DataFrame(data=principal_components, columns=[f'PC{i+1}' for i in range(n_components)])\n",
    "df = pd.concat([df, df_pca], axis=1)\n",
    "\n",
    "# Perform K-means clustering using the PCA components, and add a cluster2 column from that exercise\n",
    "kmeans2 = KMeans(n_clusters=2, random_state=0)\n",
    "df['cluster_pca_kmeans'] = kmeans.fit_predict(df[['PC1', 'PC2']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hope to see cluster group counts in the ballpark of 950 and 50\n",
    "df['cluster_pca_kmeans'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the clusters\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.scatter(df['PC1'], df['PC2'], c=df['cluster_pca_kmeans'], cmap='viridis', marker='o')\n",
    "plt.title('KMeans Clustering on PCA-Reduced Data')\n",
    "plt.xlabel('PC1')\n",
    "plt.ylabel('PC2')\n",
    "plt.colorbar(label='Cluster_pca_kmeans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try using DBSCAN clustering instead of Kmeans...we'll use cosine distance\n",
    "import pandas as pd\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "\n",
    "# Convert the embeddings column to a numpy array\n",
    "embeddings = np.array(df['embedding'].tolist())\n",
    "\n",
    "# Standardize the data (optional but recommended)\n",
    "scaler = StandardScaler()\n",
    "embeddings_scaled = scaler.fit_transform(embeddings)\n",
    "\n",
    "# Calculate the cosine distance matrix\n",
    "cosine_dist_matrix = cosine_distances(embeddings_scaled)\n",
    "\n",
    "# Perform DBSCAN clustering with cosine distance\n",
    "# Parameters to adjust: `eps` (radius of neighborhood), `min_samples` (min points to form a cluster)\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5, metric='precomputed')\n",
    "df['cluster_dbscan'] = dbscan.fit_predict(cosine_dist_matrix)\n",
    "\n",
    "# Analyzing the results\n",
    "n_clusters = len(set(df['cluster_dbscan'])) - (1 if -1 in df['cluster_dbscan'] else 0)\n",
    "n_noise = list(df['cluster_dbscan']).count(-1)\n",
    "\n",
    "print(f'Estimated number of DBSCAN clusters: {n_clusters}')\n",
    "print(f'Estimated number of noise points: {n_noise}')\n",
    "\n",
    "# If you want to see the first few entries and their clusters\n",
    "df.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hope to see cluster group counts in the ballpark of 950 and 50\n",
    "df['cluster_dbscan'].value_counts()\n",
    "\n",
    "# It appears that perhaps cluster 2 with 53 points might be our malicious logs, but...\n",
    "# I'm not sure (yet) how we would determine that if we didn't already there were 50 bad logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results after applying PCA\n",
    "\n",
    "# Reduce the embeddings to 2 dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=df['cluster_dbscan'], cmap='viridis', marker='o')\n",
    "plt.title('DBSCAN Clustering with Cosine Distance (PCA Reduced to 2D)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(scatter, label='Cluster_dbscan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's re-try Kmeans clustering, but instead of allowing it to use the default euclidean distance metric\n",
    "# we will convert the cosine similary vectors to equivalent euclidean distance vectors\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Extract the embeddings from the DataFrame\n",
    "embeddings = df['embedding'].tolist()\n",
    "\n",
    "# Normalize the embeddings to make the cosine distance equivalent to Euclidean distance\n",
    "embeddings_normalized = normalize(embeddings)\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0)  # Adjust the number of clusters as needed\n",
    "df['cluster_kmeans_cosine'] = kmeans.fit_predict(embeddings_normalized)\n",
    "\n",
    "df.columns\n",
    "# Visualize the clusters with PCA or t-SNE as discussed earlier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We hope to see cluster group counts in the ballpark of 950 and 50\n",
    "df['cluster_kmeans_cosine'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the results after applying PCA\n",
    "\n",
    "# Reduce the embeddings to 2 dimensions using PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=df['cluster_kmeans_cosine'], cmap='viridis', marker='o')\n",
    "plt.title('DBSCAN Clustering with Cosine Distance (PCA Reduced to 2D)')\n",
    "plt.xlabel('PCA Component 1')\n",
    "plt.ylabel('PCA Component 2')\n",
    "plt.colorbar(scatter, label='Cluster_Kmeans_Cosine')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've successfully demonstrated how we can do clustering analysis with full-text data.  However, there's no value in analyzing further since this is all fabricated data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Where do we got from here?\n",
    "Some areas for further research:\n",
    "- Try different embedding models to determine which one performs best with proxy logs...the one we used is very generic, one finetuned on event logs or specifically on cybersecurity data content might produce much better results.\n",
    "- Dig deeper into the data to determine how we would be able to name clusters from DBSCAN (with real data, not worthwhile with fake data).\n",
    "- Examine other clustering algorithms that might be more meaningful (with real data, not worthwhile with fake data).\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
