{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised Anomaly Detection on Security Logs using <u>Levenshtein Similarity Score</u>\n",
    "This is a continuation of the prior research. In this notebook, we are leveraging the Isolation Forest algorithm to perform unsupervised training of an anomaly detection model.  HOWEVER...we are trying this using Levenshtein similarity score INSTEAD OF using text vector embeddings as the input. I expect that this approach will be much less accurate...Levenshtein score is a scalar value that is the minimum number of distinct edits to make two text passages the same, versus a 384-dimension vector embedding output by a language-interpreting LLM that is trying to capture the meaning of the text. This is a no-AI approach to this problem, but it's worth investigating.  Will it work?  Will it come close to the known actual 950/50 split of good/bad log entries?  Let us see..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Uncomment and run the line below if this is the first time executing this notebook. Package installs in requirements.txt.\n",
    "#! python -m venv venv\n",
    "#! powershell venv\\Scripts\\Activate.ps1\n",
    "#! pip install pandas\n",
    "#! pip install matplotlib\n",
    "#! pip install sklearn\n",
    "#! pip install levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import IsolationForest\n",
    "from sklearn.metrics import pairwise_distances\n",
    "import Levenshtein as lev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein calculates the minimum number of insertions, deletions, and substitutions required to change \n",
    "# one text sequence into the other with custom costs for insertion, deletion and substitution\n",
    "# Example...should return a score of 2:\n",
    "lev.distance(\"lewenstein\", \"levenshtein\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We'll use the fabricated mixed proxy logs with known 950 benign log entries and 50 malicious log entries \n",
    "# Our goal is to see if we can get them accurately classified into that 950 benign + 50 malicious\n",
    "# Read the log data into a dataframe, and drop the columns we don't need for this exercise.\n",
    "df = pd.read_csv('proxy_logs_mixed.csv')\n",
    "df = df.drop(['IP Address', 'Timestamp'], axis=1)  # We don't need IP nor timestamp for this task\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the pairwise distance matrix\n",
    "# This creates a matrix of every row x every row and it's distance, related back to the original \n",
    "# dataframe by the ID and using Levenshtein distance as the metric. This matrix looks something like: \n",
    "#       ABC   BCD   DEF\n",
    "# ABC    0     2     6\n",
    "# BCD    2     0     4\n",
    "# DEF    6     4     0\n",
    "# For instance, the distance between ABC and BCD in edits is 1 delete and 1 insertion, for a total of 2.\n",
    "\n",
    "distance_matrix = pairwise_distances(df['Log Entry'].values.reshape(-1, 1), \n",
    "                                     metric=lambda x, y: lev.distance(x[0], y[0]))\n",
    "distance_matrix.shape # Check the shape of the matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a model object with the Isolation Forest algorithm\n",
    "# Let's favor a large number of samples and let the algorithm figure out the contamination ratio\n",
    "#model=IsolationForest(n_estimators=100,max_samples=1000,contamination='auto',random_state=96)\n",
    "model=IsolationForest(n_estimators=100,max_samples=1000,contamination='auto',random_state=96)\n",
    "\n",
    "# Fit the data to the model\n",
    "model.fit(distance_matrix)\n",
    "\n",
    "# Display parameter values that were used\n",
    "model.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a column to the DF for raw scores from the model's decision_function\n",
    "df['raw_score'] = model.decision_function(distance_matrix)\n",
    "\n",
    "# Add a column to the DF for the anomaly flag from the model's predict function...-1 indicates anomaly\n",
    "df['anomaly_score'] = model.predict(distance_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the data with the score columns added\n",
    "df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display just the anomalies\n",
    "df[df['anomaly_score']==-1].sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The outliers have anomaly_score = -1\n",
    "# This is pretty darned good, given that we know the real split is 950/50\n",
    "df['anomaly_score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of the anomaly_score results...it's what we'd expect to see given the counts above\n",
    "plt.figure(figsize=(10, 7))\n",
    "scatter = plt.scatter(df.raw_score, df.anomaly_score)\n",
    "plt.title('Anomaly Scatter Plot')\n",
    "plt.xlabel('Raw Score')\n",
    "plt.ylabel('Anomaly Score')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our unsupervised ML model, trained using a very simple distance metric that was merely the number of edits to make two text passages the same, did surprisingly well.  It flagged 70 log entries as anomalies, with 930 seen as typical.  We know the real answer from the fabricated test log entry data is 950 benign and 50 malicious.  This may be worth testing on real data and/or larger data sets, as it might be at least useable as a coarse-grained pre-filter. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
